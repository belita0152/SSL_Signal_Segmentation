# Abstract
*** Full codes coming soon! ***

While physiological signals are critical for health monitoring and affective computing, acquiring high-quality labeled data is costly and relies heavily on subjective expert judgment. Furthermore, existing methodologies predominantly focus on sliding-window-based classification, failing to precisely identify the boundaries of state transitions over time. To address these limitations, we propose a Self-Supervised Learning (SSL) framework for the Semantic Segmentation of Physiological Signals. Our approach leverages unlabeled data to learn intrinsic signal structures and patterns through pre-training, enabling the model to perform dynamic segmentation of psychological states even in label-scarce environments. We extensively evaluated our framework across multiple modalities, including ECG (Arrhythmia), EEG (Seizure), sEMG (Gesture), and Respiratory signals (Sleep Apnea) using datasets such as MIT-BIH, TUEG, Ninapro, and SHHS. The results demonstrate that our method significantly reduces label dependency while achieving precise inference of meaningful segments, paving the way for advanced real-time monitoring and clinical diagnostic aids.
